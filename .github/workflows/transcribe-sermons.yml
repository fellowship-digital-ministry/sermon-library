name: Transcribe and Embed Sermons

on:
  schedule:
    # Run every day at 7AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allows manual triggering

# Add permissions block
permissions:
  contents: write

jobs:
  transcribe:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Full history for commits
          token: ${{ secrets.PAT_TOKEN }}  # Use a Personal Access Token
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install FFmpeg
        run: sudo apt-get update && sudo apt-get install -y ffmpeg
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install required dependencies
          pip install pandas openai tqdm pydub pytube requests
          # Install the correct Pinecone package
          pip uninstall -y pinecone-client
          pip install pinecone
          # Install yt-dlp with specific version known to work better
          pip install yt-dlp==2023.12.30
      
      - name: Configure Git
        run: |
          git config --global user.name "Sermon Transcription Bot"
          git config --global user.email "fellowship-digital-ministry@proton.me"
      
      - name: Prepare YouTube Cookies
        env:
          YOUTUBE_COOKIES: ${{ secrets.YOUTUBE_COOKIES }}
        run: |
          # Create cookies file if secret is available
          if [ -n "$YOUTUBE_COOKIES" ]; then
            echo "Creating cookies file from secret..."
            echo "# Netscape HTTP Cookie File" > youtube_cookies.txt
            echo "# https://curl.haxx.se/docs/http-cookies.html" >> youtube_cookies.txt
            echo "# This file was generated by libcurl! Edit at your own risk." >> youtube_cookies.txt
            echo "" >> youtube_cookies.txt
            echo "$YOUTUBE_COOKIES" >> youtube_cookies.txt
            chmod 600 youtube_cookies.txt
            echo "Cookies file created successfully"
          else
            echo "No cookies provided in secrets"
          fi
        shell: bash
      
      - name: Run sermon monitoring with YouTube API
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          # Output current time for logging
          date
          echo "Starting sermon monitoring process using YouTube API"
          
          # Create output directories
          mkdir -p transcription/data/audio
          
          # Run the monitoring script with YouTube API - using direct channel ID
          cd transcription
          
          # Use cookies file if it exists
          if [ -f "../youtube_cookies.txt" ]; then
            COOKIES_PARAM="--cookies ../youtube_cookies.txt"
            echo "Using cookies file for authentication"
          else
            COOKIES_PARAM=""
            echo "No cookies file available"
          fi
          
          # Execute with multiple attempts and exponential backoff
          MAX_RETRIES=3
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i of $MAX_RETRIES..."
            if python monitor_channel.py \
              --youtube-api \
              --api-key "$YOUTUBE_API_KEY" \
              --channel-id "UCek_LI7dZopFJEvwxDnovJg" \
              --max 5 \
              --process \
              --cleanup \
              $COOKIES_PARAM; then
              echo "Success!"
              break
            else
              if [ $i -lt $MAX_RETRIES ]; then
                wait_time=$((i * 30))
                echo "Failed, waiting ${wait_time}s before retry..."
                sleep $wait_time
              else
                echo "All attempts failed, continuing to fallback method"
              fi
            fi
          done
        shell: bash
      
      # Add fallback method in case the API approach fails
      - name: Run fallback sermon monitoring if needed
        if: ${{ failure() }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "API approach failed, trying fallback method with yt-dlp"
          
          # Run the fallback approach
          cd transcription
          
          # Use cookies file if it exists
          if [ -f "../youtube_cookies.txt" ]; then
            COOKIES_PARAM="--cookies ../youtube_cookies.txt"
            echo "Using cookies file for authentication"
          else
            COOKIES_PARAM=""
            echo "No cookies file available"
          fi
          
          # Try different user agents and strategies
          USER_AGENTS=(
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15"
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          )
          
          # Try with different user agents
          for agent in "${USER_AGENTS[@]}"; do
            echo "Trying with user agent: $agent"
            export YT_DLP_USER_AGENT="$agent"
            
            if python monitor_channel.py \
              --channel "https://www.youtube.com/@chrismann9821" \
              --max 5 \
              --process \
              --cleanup \
              --user-agent "$agent" \
              $COOKIES_PARAM; then
              echo "Success with user agent: $agent"
              break
            else
              echo "Failed with user agent: $agent"
              sleep 30  # Wait between attempts
            fi
          done
        shell: bash
      
      # Try downloading just the audio files if the processing step failed
      - name: Download audio only as last resort
        if: ${{ failure() }}
        run: |
          echo "Trying direct audio download for recently added videos"
          
          # Use cookies file if it exists
          if [ -f "youtube_cookies.txt" ]; then
            COOKIES="--cookies youtube_cookies.txt"
          else
            COOKIES=""
          fi
          
          cd transcription
          
          # Create a Python script to download only unprocessed videos
          cat > download_pending_audio.py << 'EOF'
          import csv
          import os
          import subprocess
          
          # Read the CSV file to find pending videos
          with open('data/video_list.csv', 'r') as f:
              reader = csv.DictReader(f)
              pending_videos = [row['video_id'] for row in reader if row.get('processing_status') == 'pending']
          
          # Ensure audio directory exists
          os.makedirs('data/audio', exist_ok=True)
          
          # Try different download methods for each video
          for video_id in pending_videos:
              # Try with yt-dlp first
              try:
                  print(f"Downloading audio for {video_id}...")
                  cookies = os.environ.get('COOKIES', '')
                  
                  cmd = [
                      'yt-dlp',
                      '-x',
                      '--audio-format', 'mp3',
                      '--audio-quality', '0',
                      '-o', f'data/audio/{video_id}.%(ext)s',
                      f'https://www.youtube.com/watch?v={video_id}'
                  ]
                  
                  if cookies:
                      cmd.extend(cookies.split())
                      
                  subprocess.run(cmd, check=True)
                  print(f"Successfully downloaded {video_id}")
              except Exception as e:
                  print(f"yt-dlp failed for {video_id}: {e}")
                  
                  # Try with pytube as fallback
                  try:
                      from pytube import YouTube
                      print(f"Trying pytube for {video_id}")
                      yt = YouTube(f'https://www.youtube.com/watch?v={video_id}')
                      stream = yt.streams.filter(only_audio=True).first()
                      
                      if stream:
                          stream.download(output_path='data/audio', filename=f'{video_id}.mp4')
                          print(f"Downloaded {video_id} with pytube")
                  except Exception as e2:
                      print(f"pytube failed for {video_id}: {e2}")
          EOF
          
          # Execute the download script
          COOKIES="$COOKIES" python download_pending_audio.py
        shell: bash
      
      # Add the embedding step
      - name: Generate embeddings for new transcripts
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_ENVIRONMENT: ${{ secrets.PINECONE_ENVIRONMENT || 'us-east-1' }}
          PINECONE_INDEX_NAME: ${{ secrets.PINECONE_INDEX_NAME || 'sermon-embeddings' }}
        run: |
          python tools/transcript_to_embeddings.py --skip_existing
      
      # Update metadata in Pinecone
      - name: Update Pinecone metadata from JSON files
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_ENVIRONMENT: ${{ secrets.PINECONE_ENVIRONMENT || 'us-east-1' }}
          PINECONE_INDEX_NAME: ${{ secrets.PINECONE_INDEX_NAME || 'sermon-embeddings' }}
        run: |
          # Copy the metadata utilities to the tools directory
          cp api/metadata_utils.py tools/
          
          # Run the metadata update script for only recent changes
          python api/update_pinecone_metadata.py --only-recent --days=7
      
      # Clean up the cookies file
      - name: Clean up cookies file
        if: always()
        run: rm -f youtube_cookies.txt
      
      # First pull latest changes before committing
      - name: Pull latest changes
        run: git pull origin main
        
      - name: Commit and push changes
        run: |
          git add transcription/data/transcripts/
          git add transcription/data/metadata/
          git add transcription/data/video_list.csv
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Add new sermon transcripts and subtitles [skip ci]"
            git push
          fi