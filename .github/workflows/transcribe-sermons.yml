name: Transcribe and Embed Sermons

on:
  schedule:
    # Run every day at 7AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allows manual triggering

# Add permissions block
permissions:
  contents: write

jobs:
  transcribe:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Full history for commits
          token: ${{ secrets.PAT_TOKEN }}  # Use a Personal Access Token
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install FFmpeg
        run: sudo apt-get update && sudo apt-get install -y ffmpeg
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install required dependencies
          pip install pandas openai tqdm pydub pytube requests
          pip install pinecone
          pip install google-api-python-client
          pip install --upgrade yt-dlp
          pip install undetected-chromedriver selenium
      
      - name: Configure Git
        run: |
          git config --global user.name "Sermon Transcription Bot"
          git config --global user.email "fellowship-digital-ministry@proton.me"
      
      - name: Set up Chrome
        uses: browser-actions/setup-chrome@v1
      
      # Add caching to save API responses and reduce quota usage
      - name: Cache API responses
        uses: actions/cache@v3
        with:
          path: transcription/.api_cache
          key: youtube-api-cache-${{ github.run_id }}
          restore-keys: youtube-api-cache-
      
      # Set up cookies
      - name: Generate YouTube cookies
        id: cookies_setup
        continue-on-error: true
        run: |
          python - <<EOF
import undetected_chromedriver as uc
import time
import os
import json
import random

# Check if YOUTUBE_COOKIES_JSON is available
if os.environ.get('YOUTUBE_COOKIES_JSON'):
    print("Using provided cookies from secrets")
    with open('youtube_cookies.json', 'w') as f:
        f.write(os.environ.get('YOUTUBE_COOKIES_JSON'))
    exit(0)

print("No cookies found in secrets, will attempt to generate")

# Set up Chrome options
options = uc.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

# Add random user agent
user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
]
options.add_argument(f'--user-agent={random.choice(user_agents)}')

try:
    # Launch browser
    driver = uc.Chrome(options=options)
    
    # Visit YouTube
    driver.get('https://www.youtube.com')
    print("Opened YouTube")
    
    # Wait to ensure page loads and cookies are set
    time.sleep(5)
    
    # Get all cookies
    cookies = driver.get_cookies()
    
    # Save cookies to file
    with open('youtube_cookies.json', 'w') as f:
        json.dump(cookies, f)
    
    print(f"Saved {len(cookies)} cookies to youtube_cookies.json")
    
    # Convert to yt-dlp format
    netscape_cookies = "# Netscape HTTP Cookie File\n"
    netscape_cookies += "# https://curl.haxx.se/docs/http-cookies.html\n"
    netscape_cookies += "# This file was generated by libcurl! Edit at your own risk.\n\n"
    
    for cookie in cookies:
        domain = cookie['domain']
        flag = "TRUE" if domain.startswith('.') else "FALSE"
        path = cookie['path']
        secure = "TRUE" if cookie.get('secure', False) else "FALSE"
        expiry = cookie.get('expiry', 0)
        name = cookie['name']
        value = cookie['value']
        netscape_cookies += f"{domain}\t{flag}\t{path}\t{secure}\t{expiry}\t{name}\t{value}\n"
    
    with open('youtube_cookies.txt', 'w') as f:
        f.write(netscape_cookies)
    
    print("Converted cookies to Netscape format for yt-dlp")
    
except Exception as e:
    print(f"Error generating cookies: {e}")
    exit(1)
finally:
    try:
        driver.quit()
    except:
        pass
EOF
        env:
          YOUTUBE_COOKIES_JSON: ${{ secrets.YOUTUBE_COOKIES_JSON }}
      
      # Update monitor_channel.py to prioritize cookies
      - name: Update monitoring script
        run: |
          python - <<EOF
import re

file_path = 'transcription/monitor_channel.py'

with open(file_path, 'r') as f:
    content = f.read()

# Add code to check for cookies file at the beginning of download_video_audio
if 'def download_video_audio(' in content:
    updated_content = re.sub(
        r'def download_video_audio\(video_id: str, output_dir: str = "data/audio", cookies_file: Optional\[str\] = None\) -> bool:',
        '''def download_video_audio(video_id: str, output_dir: str = "data/audio", cookies_file: Optional[str] = None) -> bool:
    """
    Download just the audio from a YouTube video.
    First tries yt-dlp with cookies, then PyTube, then yt-dlp without cookies.
    
    Args:
        video_id: YouTube video ID
        output_dir: Directory to save the audio file
        cookies_file: Optional path to cookies file
        
    Returns:
        True if successful, False otherwise
    """
    logger.info(f"Downloading audio for video {video_id}")
    
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Check for cookies file in current directory if not provided
    if not cookies_file:
        if os.path.exists("youtube_cookies.txt"):
            cookies_file = "youtube_cookies.txt"
            logger.info(f"Using found cookies file: {cookies_file}")
    
    # If we have cookies, try yt-dlp with cookies first
    if cookies_file and os.path.exists(cookies_file):
        logger.info(f"Attempting yt-dlp download with cookies for {video_id}")
        
        args = [
            "-x",  # Extract audio
            "--audio-format", "mp3",  # Convert to MP3
            "--audio-quality", "0",  # Best quality
            "-o", f"{output_dir}/{video_id}.%(ext)s",  # Output filename
            "--no-warnings",
            # Add user agent and headers to reduce blocking
            "--user-agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "--add-header", "Accept-Language:en-US,en;q=0.9",
            # Add retries and delays
            "--retries", "5",
            "--sleep-interval", "10",
            "--max-sleep-interval", "20",
            "--cookies", cookies_file,
            f"https://www.youtube.com/watch?v={video_id}"
        ]
        
        success, output = run_yt_dlp(args, None, max_retries=2)
        if success:
            logger.info(f"Successfully downloaded {video_id} with yt-dlp and cookies")
            return True''',
        content, 1)
    
    # Also update the rest of the function to return after successful download
    if 'def download_audio_with_pytube(' in updated_content:
        updated_content = updated_content.replace(
            'if download_audio_with_pytube(video_id, output_dir):',
            '# If yt-dlp with cookies failed, try PyTube\nif download_audio_with_pytube(video_id, output_dir):'
        )
    
    with open(file_path, 'w') as f:
        f.write(updated_content)

print("Updated monitor_channel.py to prioritize cookies")
EOF
      
      # Run the monitoring with cookies
      - name: Run sermon monitoring
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          # Output current time for logging
          date
          echo "Starting sermon monitoring process using YouTube API with cookies"
          
          # Create output directories
          mkdir -p transcription/data/audio
          
          # Copy cookies to working directory
          if [ -f "youtube_cookies.txt" ]; then
            cp youtube_cookies.txt transcription/
          fi
          
          # Run the monitoring script
          cd transcription
          python monitor_channel.py \
            --youtube-api \
            --api-key "$YOUTUBE_API_KEY" \
            --channel-id "UCek_LI7dZopFJEvwxDnovJg" \
            --cookies "youtube_cookies.txt" \
            --max 5 \
            --process \
            --cleanup
      
      # Run fallback if needed
      - name: Run fallback sermon monitoring if needed
        if: ${{ failure() }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "API approach failed, trying fallback"
          
          # Run the PubSub monitoring approach
          cd transcription
          python pubsub_monitor.py
      
      # Generate embeddings
      - name: Generate embeddings for new transcripts
        if: ${{ success() }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_ENVIRONMENT: ${{ secrets.PINECONE_ENVIRONMENT || 'us-east-1' }}
          PINECONE_INDEX_NAME: ${{ secrets.PINECONE_INDEX_NAME || 'sermon-embeddings' }}
        run: |
          python tools/transcript_to_embeddings.py --skip_existing
      
      # Update metadata in Pinecone
      - name: Update Pinecone metadata from JSON files
        if: ${{ success() }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_ENVIRONMENT: ${{ secrets.PINECONE_ENVIRONMENT || 'us-east-1' }}
          PINECONE_INDEX_NAME: ${{ secrets.PINECONE_INDEX_NAME || 'sermon-embeddings' }}
        run: |
          # Copy the metadata utilities to the tools directory
          cp api/metadata_utils.py tools/
          
          # Run the metadata update script for only recent changes
          python api/update_pinecone_metadata.py --only-recent --days=7
      
      # First pull latest changes before committing
      - name: Pull latest changes
        if: ${{ success() }}
        run: git pull origin main
        
      - name: Commit and push changes
        if: ${{ success() }}
        run: |
          git add transcription/data/transcripts/
          git add transcription/data/metadata/
          git add transcription/data/video_list.csv
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Add new sermon transcripts and subtitles [skip ci]"
            git push
          fi